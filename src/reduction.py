
import codecs

def get_rules():
    do_not_reduce = [
        '土','士','工','入','八', '口', '王', '㐅', '亡', '互', '上', '下', '止'
    ]
    
    reduction_rules = [
        # Considered identical by KanjiKen
        ('⺕', '⼹'),
        ('⺲', '皿'),
        ('⺈', '𠂊'),
        ('𠆢', '人'),
        ('⼇', '丄'),
        ('艹', '卄'),
        ('⺘', '才'),
        ('龹', '关'),
        
        # Reduction Rules
        ('㇑,㇑,㇔,㇒,㇐', '业'),
        ('㇑,㇑,丶,㇒,㇀', '业'),
        ('㇑,㇑,丶,㇒,㇐', '业'),
        ('㇐,㇑,㇑,㇑,㇑', '卌'),
        ('㇐,㇑,㇑,㇐,㇐', '𠀎'),
        ('㇑,㇕,㇐,㇕,㇐', '㠯'),
        ('㇒,㇙,㇒,㇏', '𧘇'),
        ('㇕,㇑,㇑,㇐', '⿖'),
        ('㇐,㇑,㇑,㇑', '卅'),
        ('㇒,㇑,㇒,㇔', '𧘇'),
        ('人,㇐,口,人', '㑒'),
        ('人,人,人,人', '𠈌'),
        ('㇕,㇐,㇐', '彐'),
        ('㇐,㇑,㇑', '卄'),
        ('㇐,㇐,㇐', '三'),
        ('㇑,㇑,㇐', '⿚'), 
        ('㇑,㇕,㇔', '卪'),
        ('㇆,㇔,㇀', '习'),
        ('㇂,㇓,㇔', '⿘'),
        ('㇑,㇐,㇐', '土'),
        ('㇑,㇕', '⿙'),
        ('㇐,巾','帀'),
        ('㇐,㇐', '二'),
        ('㇒,㇚', '刂'),
        ('三,㇑', '龶'), # Turn into fullsize radical
        ('㇕,㇐', 'コ'),
        ('㇐,㇑', '十'),
        ('㇔,㇒', '丷'),
        ('㇔,㇔', '⺀'),
        ('㇔,㇀', '冫'),
        # ('㇒,㇔', '八'),
        
        # Questionable rules
        ('丿,丶', '冫'), # Technically correct, could lead to more issues down the line...
        
        # Probably bad rules
        # ('㇒,㇏', '人'), 
        # ('艹', '卄'), # They look the same :D
        # ('𠆢', '人'), 
        # ('⺈', '𠂊')   
    ]
    return reduction_rules, do_not_reduce